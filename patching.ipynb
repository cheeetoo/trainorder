{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd5e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import transformer_lens.patching as patching\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformer_lens import HookedTransformer\n",
    "from einops import rearrange\n",
    "\n",
    "from cfg import ExperimentConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(\n",
    "    tensor,\n",
    "    x=None,\n",
    "    y=None,\n",
    "    title=None,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    facet_labels=None,\n",
    "    facet_col=None,\n",
    "    color_continuous_midpoint=0.0,\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    reverse_y=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    data = tensor.cpu() if hasattr(tensor, \"cpu\") else np.array(tensor)\n",
    "    fig = px.imshow(\n",
    "        data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        facet_col=facet_col,\n",
    "        color_continuous_midpoint=color_continuous_midpoint,\n",
    "        color_continuous_scale=color_continuous_scale,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    if reverse_y:\n",
    "        fig.update_yaxes(autorange=\"min reversed\")\n",
    "    if title:\n",
    "        fig.update_layout(title=title)\n",
    "    if xlabel:\n",
    "        fig.update_xaxes(title=xlabel)\n",
    "    if ylabel:\n",
    "        fig.update_yaxes(title=ylabel)\n",
    "    if facet_labels and facet_col is not None:\n",
    "        for i, label in enumerate(facet_labels):\n",
    "            fig.layout.annotations[i].text = label\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfde30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "cfg = ExperimentConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_HF = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HF:\n",
    "    repo_id = \"cheeetoo/trainorder\"\n",
    "\n",
    "    hf_hub_download(repo_id, filename=\"probes.npz\", local_dir=cfg.out_dir)\n",
    "    hf_hub_download(repo_id, filename=\"aliases.json\", local_dir=cfg.out_dir)\n",
    "\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(repo_id)\n",
    "else:\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(f\"{cfg.out_dir}/final\")\n",
    "\n",
    "model = HookedTransformer.from_pretrained(cfg.model_id, hf_model=hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = np.load(f\"{cfg.out_dir}/probes.npz\")\n",
    "coef = probes[f\"{(0, cfg.num_stages - 1)}_coef\"]\n",
    "intercept = probes[f\"{(0, cfg.num_stages - 1)}_intercept\"]\n",
    "\n",
    "with open(f\"{cfg.out_dir}/aliases.json\") as f:\n",
    "    aliases = json.load(f)\n",
    "\n",
    "aliases_first = aliases[\"stage_0\"]\n",
    "aliases_last = aliases[f\"stage_{cfg.num_stages - 1}\"]\n",
    "aliases_first = random.choices(aliases_first, k=cfg.n_patching_prompts)\n",
    "aliases_last = random.choices(aliases_last, k=cfg.n_patching_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5352be",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prompts = [cfg.probe_prompt.format(a) for a in aliases_last]\n",
    "corrupted_prompts = [cfg.probe_prompt.format(a) for a in aliases_first]\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_prompts)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompts)\n",
    "\n",
    "_, clean_cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "probing_act = {}\n",
    "\n",
    "\n",
    "def save_probing_act(act, hook):\n",
    "    probing_act[\"act\"] = act[:, -1].detach()\n",
    "    return act\n",
    "\n",
    "\n",
    "model.reset_hooks(including_permanent=True)\n",
    "model.add_perma_hook(cfg.hook_point, save_probing_act)\n",
    "\n",
    "\n",
    "def get_probe_logit(act=probing_act, coef=coef, intercept=intercept):\n",
    "    return torch.mean(act[\"act\"].cpu() @ coef.T + intercept)\n",
    "\n",
    "\n",
    "_ = model(clean_tokens)\n",
    "probe_logit_clean = get_probe_logit()\n",
    "_ = model(corrupted_tokens)\n",
    "probe_logit_corrupted = get_probe_logit()\n",
    "\n",
    "\n",
    "def probing_metric(_logits):\n",
    "    return (get_probe_logit() - probe_logit_corrupted) / (\n",
    "        probe_logit_clean - probe_logit_corrupted\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_every = patching.get_act_patch_block_every(\n",
    "    model=model,\n",
    "    corrupted_tokens=corrupted_tokens,\n",
    "    clean_cache=clean_cache,\n",
    "    metric=probing_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(\n",
    "    block_every,\n",
    "    title=\"Activation Patching Per Block\",\n",
    "    x=model.to_str_tokens(cfg.probe_prompt.format(\"x y z\")),\n",
    "    xlabel=\"Position\",\n",
    "    ylabel=\"Layer\",\n",
    "    facet_col=0,\n",
    "    facet_labels=[\"Residual Stream\", \"Attn Output\", \"MLP Output\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_every = patching.get_act_patch_attn_head_all_pos_every(model, corrupted_tokens, clean_cache, probing_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cdbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(\n",
    "    attn_every,\n",
    "    title=\"Activation Patching Per Head\",\n",
    "    ylabel=\"Layer\",\n",
    "    xlabel=\"Head\",\n",
    "    facet_col=0,\n",
    "    facet_labels=[\"Output\", \"Query\", \"Key\", \"Value\", \"Pattern\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainorder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
